# Sine-Cosine-Algorithm-for-Reducing-Communication-Costs-of-Federated-Learning
**Abstract**

Federated learning (FL) is a setting for machine learning (ML) in which several clients (e.g., mobile devices) train a model cooperatively under the direction of a central server (e.g., cloud server), while training data is decentralized. Due to the fact that FL clients frequently have restricted transmission capacity, communication among clients and servers needs to be reduced to enhance presentation. FL clients frequently employ Wi-Fi and must interact in Unstable Network Environment (UNE). Existing FL aggregation techniques send and receive a huge number of weights, which dramatically reduces the accuracy of UNE. In this paper, we propose a federated Sine Cosine Algorithm (FedSCA) algorithm to reduce data communication by transferring score principles rather than all client models' weights and utilizing the Sine Cosine Algorithm (SCA) mechanism as a weights update technique to improve the clients' models. This paper reveals that using FedSCA significantly decreases the quantity of data utilized in network communication and increases the global model's accuracy by an average of 9.87\% over FedAvg and 2.29\% over FedPSO. Moreover, in studies conducted on an unstable network, it demonstrated a 4.3\% improvement in accuracy loss existing algorithms.

**Dataset:** https://www.cs.toronto.edu/~kriz/cifar.html


**Authors:**

Ammar Kamal Abasi, Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), UAE. E-mail:ammar.abasi@mbzuai.ac.ae

Moayad Aloqaily, Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), UAE. E-mail: maloqaily@ieee.org

Mohsen Guizani, Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), UAE. E-mail: mguizani@ieee.org
